{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alexandria', 'Assiut', 'Aswan', 'Behera', 'Beni Suef', 'Cairo', 'Dakahlia', 'Damietta', 'Fayoum', 'Gharbia', 'Giza', 'Ismailia', 'Kafr El-Shikh', 'Kalyoubia', 'Luxor', 'Matrouh', 'Menia', 'Menoufia', 'New Valley', 'North Sinai', 'Port Said', 'Qena', 'Red Sea', 'Sharkia', 'South Sinai', 'Suez', 'Suhag']\n"
     ]
    }
   ],
   "source": [
    "# Replace 'geojson_data.json' with the path to your actual GeoJSON file\n",
    "json_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/governorates.json'\n",
    "\n",
    "try:\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extracting ADM1_EN values from features\n",
    "    adm1_en_values = [feature['properties']['ADM1_EN'] for feature in data['features']]\n",
    "    print(adm1_en_values)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"The file {json_file_path} does not exist.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"The file {json_file_path} is not a valid JSON or GeoJSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\n",
    "    \"6 October-1 (k)\",\n",
    "    \"6 October-2 (k)\",\n",
    "    \"10 Ramadan 1 (k)\",\n",
    "    \"10 Ramadan 2 (k)\",\n",
    "    \"15 Mayu (k)\",\n",
    "    \"Abdin (k)\",\n",
    "    \"Abnub (m)\",\n",
    "    \"Abu-l-Matamir (m)\",\n",
    "    \"Abu Hammad (m)\",\n",
    "    \"Abu Hummus (m)\",\n",
    "    \"Abu Kebir (m)\",\n",
    "    \"Abu Qirqas (m)\",\n",
    "    \"Abu Radis (k)\",\n",
    "    \"Abu Simbel (m)\",\n",
    "    \"Abu Tig (m)\",\n",
    "    \"Abu Tisht (m)\",\n",
    "    \"Abu Zenima (k)\",\n",
    "    \"Aga (m)\",\n",
    "    \"Al-Aguza (k)\",\n",
    "    \"Ain Shams (k)\",\n",
    "    \"Akhmim City (m)\",\n",
    "    \"Alexandria Port Police Department (p)\",\n",
    "    \"Amreya (k)\",\n",
    "    \"El Arish 1 (k)\",\n",
    "    \"El Arish 2 (k)\",\n",
    "    \"El Arish 3 (k)\",\n",
    "    \"El Arish 4 (k)\",\n",
    "    \"Armant (m)\",\n",
    "    \"Ashmun (m)\",\n",
    "    \"Aswan City (k)\",\n",
    "    \"Aswan (m)\",\n",
    "    \"Assuit (m)\",\n",
    "    \"Assuit City 1 (k)\",\n",
    "    \"Assuit City 2 (k)\",\n",
    "    \"Ataqa (k)\",\n",
    "    \"Atfeh (m)\",\n",
    "    \"Awlad Saqr (m)\",\n",
    "    \"Awsim (m)\",\n",
    "    \"Al-Azbakiyya (k)\",\n",
    "    \"Bab Al-Shariyya (k)\",\n",
    "    \"Bab Sharqi (k)\",\n",
    "    \"Badrashain (k)\",\n",
    "    \"Badr (m)\",\n",
    "    \"Banha (k)\",\n",
    "    \"Banha (m)\",\n",
    "    \"Baris Police (m)\",\n",
    "    \"Basyun (m)\",\n",
    "    \"Bany Abeed (m)\",\n",
    "    \"Beni Mazar (m)\",\n",
    "    \"Bani Swayf City (k)\",\n",
    "    \"Bani Swayf (m)\",\n",
    "    \"Biba (m)\",\n",
    "    \"Bilbis (m)\",\n",
    "    \"Bilqas (m)\",\n",
    "    \"Bir Al-Abd (k)\",\n",
    "    \"Birkat Al-Sab (m)\",\n",
    "    \"Biyalu (m)\",\n",
    "    \"Burg al-Arab (m)\",\n",
    "    \"Burg Al-Arab City (k)\",\n",
    "    \"Bulaq (k)\",\n",
    "    \"Bulaq Al-DakrUr (k)\",\n",
    "    \"Burullus (m)\",\n",
    "    \"Dahab (k)\",\n",
    "    \"Dayrut (m)\",\n",
    "    \"Damanhur (k)\",\n",
    "    \"Damanhur (m)\",\n",
    "    \"Dumyat (m)\",\n",
    "    \"Dumyat 1 (k)\",\n",
    "    \"Dumyat 2 (k)\",\n",
    "    \"Dar al-Salam (m)\",\n",
    "    \"Daraw (m)\",\n",
    "    \"Deir Mawas (m)\",\n",
    "    \"Dikirnis (m)\",\n",
    "    \"Dekhela (k)\",\n",
    "    \"Disuq (k)\",\n",
    "    \"Disuq (m)\",\n",
    "    \"Dishna (m)\",\n",
    "    \"Dyarb Nigm (m)\",\n",
    "    \"Dokki (k)\",\n",
    "    \"Edfu (m)\",\n",
    "    \"Edku (m)\",\n",
    "    \"Al-Ahram (k)\",\n",
    "    \"Al-Arab (k)\",\n",
    "    \"Al-Arbiin (k)\",\n",
    "    \"Al-Attarin (k)\",\n",
    "    \"El Ayyat (m)\",\n",
    "    \"Al- Badari (m)\",\n",
    "    \"Al-Badrashein (m)\",\n",
    "    \"Al-Bagur (m)\",\n",
    "    \"Al-Balyana (m)\",\n",
    "    \"El Basal Port (k)\",\n",
    "    \"Al-Basatin (k)\",\n",
    "    \"Al-Dabaa (k)\",\n",
    "    \"Al-Dar Al-Ahmar (k)\",\n",
    "    \"Al-Dawahy (k)\",\n",
    "    \"Al-Dilingat (m)\",\n",
    "    \"Al-Fashn (m)\",\n",
    "    \"Al-Fath (m)\",\n",
    "    \"Al-Gamaliya (k)\",\n",
    "    \"Al-Gamaliya (m)\",\n",
    "    \"Al-Ganayin (k)\",\n",
    "    \"Al-Ghanayem (m)\",\n",
    "    \"Al-Gomrok (k)\",\n",
    "    \"Al-Hammam (k)\",\n",
    "    \"Al-Hamool (m)\",\n",
    "    \"Al-Hasna (k)\",\n",
    "    \"Al-Hawamdiya (k)\",\n",
    "    \"Al-Husayniya (m)\",\n",
    "    \"El-Ibrahimiya (m)\",\n",
    "    \"Al-Idwa (m)\",\n",
    "    \"Al-Kawsar (k)\",\n",
    "    \"Al-Khalifa (k)\",\n",
    "    \"Al-Labban (k)\",\n",
    "    \"El Mahalla El Kobra (m)\",\n",
    "    \"El Mahalla El Kobra 1 (k)\",\n",
    "    \"El Mahalla El Kobra 2 (k)\",\n",
    "    \"Al-Mahmudiyya (m)\",\n",
    "    \"Al-Manakh (k)\",\n",
    "    \"Al-Manasra (k)\",\n",
    "    \"Al-Mansha (m)\",\n",
    "    \"El-Mansheya (k)\",\n",
    "    \"Al-Manzala (m)\",\n",
    "    \"Al-Maragha (m)\",\n",
    "    \"El-Marg (k)\",\n",
    "    \"El-Matariyya (k)\",\n",
    "    \"El-Matariyya (m)\",\n",
    "    \"Al-Muski (k)\",\n",
    "    \"El-Nozha (k)\",\n",
    "    \"El-Omraniya (k)\",\n",
    "    \"Al-Qanater Al-Khayreya (m)\",\n",
    "    \"Al-Qanayat (k)\",\n",
    "    \"El-Qantara (m)\",\n",
    "    \"El-Qantara Al-Sharqiya (k)\",\n",
    "    \"El-Qoseir (k)\",\n",
    "    \"El-Qurain (k)\",\n",
    "    \"Al-Qusia (m)\",\n",
    "    \"Al-Rahmaniyya (m)\",\n",
    "    \"El-Raml 1 (k)\",\n",
    "    \"El-Raml 2 (k)\",\n",
    "    \"Al-Reyad (m)\",\n",
    "    \"Al-Saff (m)\",\n",
    "    \"Al-Salam (k)\",\n",
    "    \"Al-Santa (m)\",\n",
    "    \"Al-Sayeda Zeinab (k)\",\n",
    "    \"El-Segil (k)\",\n",
    "    \"Al-Senbellawein (m)\",\n",
    "    \"El-Sharabiya (k)\",\n",
    "    \"El-Sharq (k)\",\n",
    "    \"El-Shohada (m)\",\n",
    "    \"El-Shorouk (k)\",\n",
    "    \"El-Tebbin (k)\",\n",
    "    \"El-Tor (k)\",\n",
    "    \"Al-Usayrat (m)\",\n",
    "    \"Al-Wahat El-Bahariya (k)\",\n",
    "    \"Al-Wahat El-Khariga (k)\",\n",
    "    \"Al-Waqf (m)\",\n",
    "    \"El-Warraq (k)\",\n",
    "    \"Al-Wasta (m)\",\n",
    "    \"El-Weili (k)\",\n",
    "    \"El-Zaher (k)\",\n",
    "    \"El-Zarqa (m)\",\n",
    "    \"Al-Zawya El-Hamra (k)\",\n",
    "    \"El-Zohur (k)\",\n",
    "    \"Esna (m)\",\n",
    "    \"Faysal (k)\",\n",
    "    \"Fayyum (k)\",\n",
    "    \"Fayyum City (m)\",\n",
    "    \"Faqus (k)\",\n",
    "    \"Faqus (m)\",\n",
    "    \"Fariskur (m)\",\n",
    "    \"Farshut (m)\",\n",
    "    \"Fayid (m)\",\n",
    "    \"Fuwwa (m)\",\n",
    "    \"Gamsa (k)\",\n",
    "    \"Al-Ganoub (k)\",\n",
    "    \"Al-Ganoub 1 (k)\",\n",
    "    \"Al-Ganoub 2 (k)\",\n",
    "    \"Gharb Nubariya (k)\",\n",
    "    \"Girga (k)\",\n",
    "    \"Girga (m)\",\n",
    "    \"Giza (k)\",\n",
    "    \"Giza (m)\",\n",
    "    \"Hada'iq Al-Qubba (k)\",\n",
    "    \"Halayib (k)\",\n",
    "    \"Heliopolis (k)\",\n",
    "    \"Hilwan (k)\",\n",
    "    \"Hihya (m)\",\n",
    "    \"Hosh Essa (m)\",\n",
    "    \"Hurghada 1 (k)\",\n",
    "    \"Hurghada 2 (k)\",\n",
    "    \"Ibsheway (m)\",\n",
    "    \"Ihnasiya (m)\",\n",
    "    \"Imbaba (k)\",\n",
    "    \"Imbaba (m)\",\n",
    "    \"Ismailiyya (m)\",\n",
    "    \"Ismailiyya 1 (k)\",\n",
    "    \"Ismailiyya 2 (k)\",\n",
    "    \"Ismailiyya 3 (k)\",\n",
    "    \"Itay Al-Barud (m)\",\n",
    "    \"Itsa (m)\",\n",
    "    \"Juhayna (m)\",\n",
    "    \"Kafr Al-Dawwar (k)\",\n",
    "    \"Kafr Al-Dawwar (m)\",\n",
    "    \"Kafr Al-Shaykh (k)\",\n",
    "    \"Kafr Al-Shaykh (m)\",\n",
    "    \"Kafr Al-Zayyat (m)\",\n",
    "    \"Kafr Sad (m)\",\n",
    "    \"Kafr Saqr (m)\",\n",
    "    \"Kafr Shukr (m)\",\n",
    "    \"Karmuz (k)\",\n",
    "    \"Kardasa (m)\",\n",
    "    \"Khanka (m)\",\n",
    "    \"Khsos (k)\",\n",
    "    \"Kum Hamada (m)\",\n",
    "    \"Kum Umbu (m)\",\n",
    "    \"Kotoor (m)\",\n",
    "    \"Luxor (k)\",\n",
    "    \"Luxor (m)\",\n",
    "    \"Maadi (k)\",\n",
    "    \"Maghaghah (m)\",\n",
    "    \"Mahallat Dimna (m)\",\n",
    "    \"Mallawi (k)\",\n",
    "    \"Mallawi (m)\",\n",
    "    \"Manfalut (m)\",\n",
    "    \"El Mansora (m)\",\n",
    "    \"El Mansora 1 (k)\",\n",
    "    \"E Mansora 2 (k)\",\n",
    "    \"Marina El-Alamein (k)\",\n",
    "    \"Marsa Alam (k)\",\n",
    "    \"Mashtool El-Souk (m)\",\n",
    "    \"Matay (m)\",\n",
    "    \"Minuf (k)\",\n",
    "    \"Minuf (m)\",\n",
    "    \"Marsa Matruh (k)\",\n",
    "    \"Metoubes (m)\",\n",
    "    \"Minya (k)\",\n",
    "    \"Minya (m)\",\n",
    "    \"Minya al-Qamh (m)\",\n",
    "    \"Minya Al-Nasr (m)\",\n",
    "    \"Mit Ghamr (k)\",\n",
    "    \"Mit Ghamr (m)\",\n",
    "    \"Mit Salsil (m)\",\n",
    "    \"Moharam Bek (k)\",\n",
    "    \"Manshat Al-Nasr (k)\",\n",
    "    \"Montaza (k)\",\n",
    "    \"Mubarak East El-Tafrea (k)\",\n",
    "    \"Nabaroh (m)\",\n",
    "    \"Nag Hammadi (m)\",\n",
    "    \"Nakhl (k)\",\n",
    "    \"Naqada (m)\",\n",
    "    \"Nasir Bush (m)\",\n",
    "    \"Nasr (m)\",\n",
    "    \"Nasr City (k)\",\n",
    "    \"Nasr City 1 (k)\",\n",
    "    \"Nasr City 2 (k)\",\n",
    "    \"New Akhmim (n)\",\n",
    "    \"New Aswan (n)\",\n",
    "    \"New Asyut (n)\",\n",
    "    \"New Beni Suef (k)\",\n",
    "    \"New Borg El-Arab (n)\",\n",
    "    \"New Cairo-1 (k)\",\n",
    "    \"New Cairo-2 (k)\",\n",
    "    \"New Cairo-3 (k)\",\n",
    "    \"New Damietta (k)\",\n",
    "    \"New Faiyum (n)\",\n",
    "    \"New Minya (n)\",\n",
    "    \"New Qena (n)\",\n",
    "    \"New Salhia (k)\",\n",
    "    \"New Sohag (n)\",\n",
    "    \"New Toshka (n)\",\n",
    "    \"North Coast (k)\",\n",
    "    \"Nuweiba (k)\",\n",
    "    \"Obour (k)\",\n",
    "    \"Old Cairo (k)\",\n",
    "    \"Port Fuad 1 (k)\",\n",
    "    \"Port Fuad 2 (k)\",\n",
    "    \"Suez Port Police Department (p)\",\n",
    "    \"Qaha (k)\",\n",
    "    \"Qillin (m)\",\n",
    "    \"Qalyub (k)\",\n",
    "    \"Qalyub (m)\",\n",
    "    \"Qasr Al-Nile (k)\",\n",
    "    \"Qina (k)\",\n",
    "    \"Qina (m)\",\n",
    "    \"Qift (m)\",\n",
    "    \"Quwisna (m)\",\n",
    "    \"Qus (m)\",\n",
    "    \"Rafah (k)\",\n",
    "    \"Ras al-Bar (k)\",\n",
    "    \"Ras Gharib (k)\",\n",
    "    \"Ras Sidr (k)\",\n",
    "    \"Rud Al-Farag (k)\",\n",
    "    \"Rosetta (m)\",\n",
    "    \"Sadat City (m)\",\n",
    "    \"Safaga (k)\",\n",
    "    \"Sahil Salim (m)\",\n",
    "    \"Sant Katrin (k)\",\n",
    "    \"Salloum (k)\",\n",
    "    \"Samalut (m)\",\n",
    "    \"Samannud (m)\",\n",
    "    \"Saqultah (m)\",\n",
    "    \"Sirs Al-Layyana City (k)\",\n",
    "    \"Shallatin (k)\",\n",
    "    \"Sharm el-Sheikh (k)\",\n",
    "    \"Shaykh Zayed (k)\",\n",
    "    \"Shaykh Zuwayd (k)\",\n",
    "    \"Shibin al-Kum (k)\",\n",
    "    \"Shibin al-Kum (m)\",\n",
    "    \"Shibin al-Qanatir (m)\",\n",
    "    \"Shirbin (m)\",\n",
    "    \"Shubra (k)\",\n",
    "    \"Shubra Al-Khayma 1 (k)\",\n",
    "    \"Shubra Al-Khayma 2 (k)\",\n",
    "    \"Shubra Khît (m)\",\n",
    "    \"Dakhla Oasis Police (m)\",\n",
    "    \"Farafra Oasis Police (m)\",\n",
    "    \"Qasima Police (k)\",\n",
    "    \"Rummana Police (k)\",\n",
    "    \"Sidfa (m)\",\n",
    "    \"Sidi Barani (k)\",\n",
    "    \"Sidi Gabir (k)\",\n",
    "    \"Sidi Salim (m)\",\n",
    "    \"Sinuras (m)\",\n",
    "    \"Siwa (k)\",\n",
    "    \"Suhag City (m)\",\n",
    "    \"Suhag (m)\",\n",
    "    \"Suhag1 (k)\",\n",
    "    \"Suhag-2 (k)\",\n",
    "    \"Suez (k)\",\n",
    "    \"Suez Port Police Department (p)\",\n",
    "    \"Sumusta As-Suq (m)\",\n",
    "    \"Taba (k)\",\n",
    "    \"Tahta (k)\",\n",
    "    \"Tahta (m)\",\n",
    "    \"Tala (m)\",\n",
    "    \"Talkha (m)\",\n",
    "    \"Tamya (m)\",\n",
    "    \"Tanta (m)\",\n",
    "    \"Tanta 1 (k)\",\n",
    "    \"Tanta 2 (k)\",\n",
    "    \"Tell El Kebir (m)\",\n",
    "    \"Tiba police station (m)\",\n",
    "    \"Tama (m)\",\n",
    "    \"Tamy Al-Amdid (m)\",\n",
    "    \"Tukh (m)\",\n",
    "    \"Tura (k)\",\n",
    "    \"Wadi Al-NatrUn (m)\",\n",
    "    \"Yousef El sadeq (m)\",\n",
    "    \"Zaqaziq (m)\",\n",
    "    \"Zaqaziq 1 (k)\",\n",
    "    \"Zaqaziq 2 (k)\",\n",
    "    \"Zamalik (k)\",\n",
    "    \"Zifta (m)\",\n",
    "    \"Zeitoun (k)\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the type of a municipal division\n",
    "def get_municipal_division_type(municipal_divisions_name_EN):\n",
    "    # Dictionary to hold the mapping of municipal division names to their types\n",
    "    division_type_mapping = {}\n",
    "    for item in list1:\n",
    "        name, division_type = item.rsplit(\" \", 1)\n",
    "        division_type = division_type.strip(\"()\")\n",
    "        division_type_mapping[name] = division_type\n",
    "\n",
    "    # Mapping the types to full form\n",
    "    type_full_form = {\n",
    "        'k': 'kism',\n",
    "        'm': 'markaz',\n",
    "        'n': 'new city',\n",
    "        'p': 'police-administered'\n",
    "    }\n",
    "    \n",
    "    # Check if the municipal division name is in the dictionary\n",
    "    if municipal_divisions_name_EN in division_type_mapping:\n",
    "        division_type = division_type_mapping[municipal_divisions_name_EN]\n",
    "        return type_full_form.get(division_type, \"Unknown type\")\n",
    "    else:\n",
    "        return \"Division not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your actual GeoJSON file\n",
    "json_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/regions.json'\n",
    "csv_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/csv/municipal_divisions.csv'\n",
    "json_output_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/municipal_divisions_output.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/regions.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    csv_data = []\n",
    "    for feature in data['features']:\n",
    "        # Extract the first (exterior) ring of the polygon\n",
    "        exterior_ring = feature['geometry']['coordinates'][0]\n",
    "        \n",
    "        # Pick a random point from the exterior ring\n",
    "        if exterior_ring:  # Check if the exterior ring is not empty\n",
    "            random_point = random.choice(exterior_ring)\n",
    "            # Check if random_point is a list of lists\n",
    "            if isinstance(random_point[0], list):\n",
    "                random_point = random.choice(random_point)\n",
    "            latitude, longitude = random_point[1], random_point[0]  # Assuming [longitude, latitude] order\n",
    "        else:\n",
    "            latitude, longitude = None, None\n",
    "        \n",
    "        csv_row = {\n",
    "            'governorate_EN': feature['properties']['ADM1_EN'],\n",
    "            'governorate_AR': feature['properties']['ADM1_AR'],\n",
    "            'governorate_PCODE': feature['properties']['ADM1_PCODE'],\n",
    "            'municipal_divisions_type': get_municipal_division_type(feature['properties']['ADM2_EN']),\n",
    "            'municipal_divisions_name_EN': feature['properties'].get('ADM2_EN', ''), \n",
    "            'municipal_divisions_name_AR': feature['properties'].get('ADM2_AR', ''),\n",
    "            'municipal_divisions_name_PCODE': feature['properties'].get('ADM2_PCODE', ''),\n",
    "            \"Country_EN\": feature['properties']['ADM0_EN'],\n",
    "            \"Country_AR\": feature['properties']['ADM0_AR'],\n",
    "            \"Country_PCODE\": feature['properties']['ADM0_PCODE'],\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude\n",
    "        }\n",
    "        csv_data.append(csv_row)\n",
    "    \n",
    "    df = pd.DataFrame(csv_data)\n",
    "    print(df.head())\n",
    "    \n",
    "    os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "    print(f\"Data successfully written to {csv_file_path}\")\n",
    "    \n",
    "    with open(json_output_path, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(csv_data, jsonfile, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data successfully written to {json_output_path}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"The file {json_file_path} does not exist.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"The file {json_file_path} is not a valid JSON or GeoJSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kism'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_municipal_division_type(\"10 Ramadan 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ID690',\n",
       "  'projectNo': 690,\n",
       "  'projectName': 'Project 690',\n",
       "  'projectDetail': 'Detail of project 690',\n",
       "  'photoURL': 'https://picsum.photos/250?image=24',\n",
       "  'executingAgency': 'Agency',\n",
       "  'status': 'pending',\n",
       "  'theme': ['H_D'],\n",
       "  'estimatedCost': 91489,\n",
       "  'budget': 61591,\n",
       "  'totalDonatedAmount': 61405,\n",
       "  'startDate': '2024-01-15',\n",
       "  'endDate': '2024-02-19',\n",
       "  'Latitude': -67.417251,\n",
       "  'Longitude': -5.628984,\n",
       "  'City_Name_EN': 'City',\n",
       "  'City_Name_AR': 'مدينة',\n",
       "  'City_Name_PCODE': '',\n",
       "  'City_PCODE': '',\n",
       "  'State_Name_EN': 'State',\n",
       "  'State_Name_AR': 'حالة',\n",
       "  'State_Name_PCODE': '',\n",
       "  'Region_Name_EN': 'Region',\n",
       "  'Region_Name_AR': 'منطقة',\n",
       "  'Region_PCODE': '',\n",
       "  'Locality_Name_EN': 'Locality',\n",
       "  'Locality_Name_AR': 'محلية',\n",
       "  'Locality_PCODE': '',\n",
       "  'Province_Name_EN': 'Province',\n",
       "  'Province_Name_AR': 'محافظة',\n",
       "  'Province_PCODE': '',\n",
       "  'municipal_divisions_type': '',\n",
       "  'municipal_divisions_name_EN': '',\n",
       "  'municipal_divisions_name_AR': '',\n",
       "  'municipal_divisions_name_PCODE': '',\n",
       "  'Governorate_Name_EN': 'New Valley',\n",
       "  'Governorate_Name_AR': 'محافظة',\n",
       "  'Governorate_PCODE': '',\n",
       "  'District_Name_EN': 'District',\n",
       "  'District_Name_AR': 'منطقة',\n",
       "  'District_PCODE': '',\n",
       "  'Country_EN': 'Country',\n",
       "  'Country_AR': 'بلد',\n",
       "  'Country_PCODE': '',\n",
       "  'donor': 'Donor',\n",
       "  'contribution': 'Contribution',\n",
       "  'dataReliability': 'High'},\n",
       " {'id': 'ID24',\n",
       "  'projectNo': 24,\n",
       "  'projectName': 'Project 24',\n",
       "  'projectDetail': 'Detail of project 24',\n",
       "  'photoURL': 'https://picsum.photos/250?image=100',\n",
       "  'executingAgency': 'Agency',\n",
       "  'status': 'pending',\n",
       "  'theme': ['H_D'],\n",
       "  'estimatedCost': 63537,\n",
       "  'budget': 21411,\n",
       "  'totalDonatedAmount': 30575,\n",
       "  'startDate': '2024-05-29',\n",
       "  'endDate': '2025-10-03',\n",
       "  'Latitude': 29.291013,\n",
       "  'Longitude': 159.340774,\n",
       "  'City_Name_EN': 'City',\n",
       "  'City_Name_AR': 'مدينة',\n",
       "  'City_Name_PCODE': '',\n",
       "  'City_PCODE': '',\n",
       "  'State_Name_EN': 'State',\n",
       "  'State_Name_AR': 'حالة',\n",
       "  'State_Name_PCODE': '',\n",
       "  'Region_Name_EN': 'Region',\n",
       "  'Region_Name_AR': 'منطقة',\n",
       "  'Region_PCODE': '',\n",
       "  'Locality_Name_EN': 'Locality',\n",
       "  'Locality_Name_AR': 'محلية',\n",
       "  'Locality_PCODE': '',\n",
       "  'Province_Name_EN': 'Province',\n",
       "  'Province_Name_AR': 'محافظة',\n",
       "  'Province_PCODE': '',\n",
       "  'municipal_divisions_type': '',\n",
       "  'municipal_divisions_name_EN': '',\n",
       "  'municipal_divisions_name_AR': '',\n",
       "  'municipal_divisions_name_PCODE': '',\n",
       "  'Governorate_Name_EN': 'Cairo',\n",
       "  'Governorate_Name_AR': 'محافظة',\n",
       "  'Governorate_PCODE': '',\n",
       "  'District_Name_EN': 'District',\n",
       "  'District_Name_AR': 'منطقة',\n",
       "  'District_PCODE': '',\n",
       "  'Country_EN': 'Country',\n",
       "  'Country_AR': 'بلد',\n",
       "  'Country_PCODE': '',\n",
       "  'donor': 'Donor',\n",
       "  'contribution': 'Contribution',\n",
       "  'dataReliability': 'High'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice, randint\n",
    "import datetime\n",
    "\n",
    "# Define lists for random selection\n",
    "themes = [\"R_C\", \"D_E\", \"E_E\", \"H_D\", \"P_S\", \"I_D\"]\n",
    "governorates = [\"Alexandria\", \"Assiut\", \"Aswan\", \"Behera\", \"Beni Suef\", \"Cairo\", \"Dakahlia\", \"Damietta\", \n",
    "                \"Fayoum\", \"Gharbia\", \"Giza\", \"Ismailia\", \"Kafr El-Shikh\", \"Kalyoubia\", \"Luxor\", \"Matrouh\", \n",
    "                \"Menia\", \"Menoufia\", \"New Valley\", \"North Sinai\", \"Port Said\", \"Qena\", \"Red Sea\", \"Sharkia\", \n",
    "                \"South Sinai\", \"Suez\", \"Suhag\"]\n",
    "status_options = [\"current\", \"completed\", \"pending\"]\n",
    "\n",
    "# Function to generate random dates\n",
    "def random_date(start, end):\n",
    "    return start + datetime.timedelta(days=randint(0, (end - start).days))\n",
    "\n",
    "# Dummy data generator function\n",
    "def generate_dummy_data(num_records=10):\n",
    "    dummy_data = []\n",
    "    start_date = datetime.date(2020, 1, 1)\n",
    "    end_date = datetime.date(2025, 12, 31)\n",
    "    \n",
    "    for _ in range(num_records):\n",
    "        project_no = randint(1, 1000)\n",
    "        start = random_date(start_date, end_date - datetime.timedelta(days=365))  # Ensure start before end\n",
    "        end = random_date(start + datetime.timedelta(days=1), end_date)  # End after start\n",
    "        governorate = choice(governorates)\n",
    "        \n",
    "        data = {\n",
    "            \"id\": f\"ID{project_no}\",\n",
    "            \"projectNo\": project_no,\n",
    "            \"projectName\": f\"Project {project_no}\",\n",
    "            \"projectDetail\": f\"Detail of project {project_no}\",\n",
    "            \"photoURL\": f\"https://picsum.photos/250?image={randint(1, 100)}\",\n",
    "            \"executingAgency\": \"Agency\",\n",
    "            \"status\": choice(status_options),\n",
    "            \"theme\": [choice(themes)],\n",
    "            \"estimatedCost\": randint(1000, 100000),\n",
    "            \"budget\": randint(1000, 100000),\n",
    "            \"totalDonatedAmount\": randint(1000, 100000),\n",
    "            \"startDate\": start.isoformat(),\n",
    "            \"endDate\": end.isoformat(),\n",
    "            \"Latitude\": float(f\"{randint(-90, 90)}.{randint(1, 999999)}\"),\n",
    "            \"Longitude\": float(f\"{randint(-180, 180)}.{randint(1, 999999)}\"),\n",
    "            \"City_Name_EN\": \"City\",\n",
    "            \"City_Name_AR\": \"مدينة\",\n",
    "            \"City_Name_PCODE\": \"\",\n",
    "            \"City_PCODE\": \"\",\n",
    "            \"State_Name_EN\": \"State\",\n",
    "            \"State_Name_AR\": \"حالة\",\n",
    "            \"State_Name_PCODE\": \"\",\n",
    "            \"Region_Name_EN\": \"Region\",\n",
    "            \"Region_Name_AR\": \"منطقة\",\n",
    "            \"Region_PCODE\": \"\",\n",
    "            \"Locality_Name_EN\": \"Locality\",\n",
    "            \"Locality_Name_AR\": \"محلية\",\n",
    "            \"Locality_PCODE\": \"\",\n",
    "            \"Province_Name_EN\": \"Province\",\n",
    "            \"Province_Name_AR\": \"محافظة\",\n",
    "            \"Province_PCODE\": \"\",\n",
    "            \"municipal_divisions_type\": \"\",\n",
    "            \"municipal_divisions_name_EN\": \"\",\n",
    "            \"municipal_divisions_name_AR\": \"\",\n",
    "            \"municipal_divisions_name_PCODE\": \"\",\n",
    "            \"Governorate_Name_EN\": governorate,\n",
    "            \"Governorate_Name_AR\": \"محافظة\",\n",
    "            \"Governorate_PCODE\": \"\",\n",
    "            \"District_Name_EN\": \"District\",\n",
    "            \"District_Name_AR\": \"منطقة\",\n",
    "            \"District_PCODE\": \"\",\n",
    "            \"Country_EN\": \"Country\",\n",
    "            \"Country_AR\": \"بلد\",\n",
    "            \"Country_PCODE\": \"\",\n",
    "            \"donor\": \"Donor\",\n",
    "            \"contribution\": \"Contribution\",\n",
    "            \"dataReliability\": \"High\"\n",
    "        }\n",
    "        dummy_data.append(data)\n",
    "    \n",
    "    return dummy_data\n",
    "\n",
    "# Generate 10 dummy records\n",
    "dummy_data = generate_dummy_data(10)\n",
    "dummy_data[:2]  # Display first two records to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CSV input and JSON output file names\n",
    "csv_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/csv/trial2.csv'\n",
    "json_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/project_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "# Open the file in binary mode and read a portion to detect its encoding\n",
    "with open(csv_file_path, 'rb') as file:\n",
    "    result = chardet.detect(file.read(10000))  # Reading the first 10000 bytes\n",
    "\n",
    "# Extract the encoding\n",
    "encoding = result['encoding']\n",
    "print(\"Detected encoding:\", encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "executingAgency = [\n",
    "    {\n",
    "        \"executingAgencyName\": \"UNDP\",\n",
    "        \"executingAgencyDepartment\": \"Accelerator Lab\",\n",
    "        \"executingAgencyTeam\": \"Exploration Team\",\n",
    "        \"executingAgencyEmail\": \"undp@undp.org\",\n",
    "        \"executingAgencyWebsite\": \"https://www.undp.org\",\n",
    "        \"executingAgencyPhotoUrl\": \"data:image/png;base64,[image_data]\",\n",
    "        \"executingAgencyProjectList\": [\"Project1\", \"Project2\", \"Project3\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "donors = [\n",
    "    {\n",
    "        \"donorName\": \"Donor1 name\",\n",
    "        \"donorEmail\": \"email@undp.org\",\n",
    "        \"donorWebsite\": \"https://www.undp.org\",\n",
    "        \"donorPhotoUrl\": \"data:image/png;base64,[image_data]\",\n",
    "        \"donorProjectList\": [\"Project1\", \"Project2\", \"Project3\"],\n",
    "        \"donationAmount\": 2500\n",
    "    },\n",
    "    {\n",
    "        \"donorName\": \"Donor2 name\",\n",
    "        \"donorEmail\": \"email@undp.org\",\n",
    "        \"donorWebsite\": \"https://www.undp.org\",\n",
    "        \"donorPhotoUrl\": \"data:image/png;base64,[image_data]\",\n",
    "        \"donorProjectList\": [\"Project1\", \"Project2\", \"Project3\"],\n",
    "        \"donationAmount\": 2500\n",
    "    },\n",
    "    {\n",
    "        \"donorName\": \"Donor3 name\",\n",
    "        \"donorEmail\": \"email@undp.org\",\n",
    "        \"donorWebsite\": \"https://www.undp.org\",\n",
    "        \"donorPhotoUrl\": \"data:image/png;base64,[image_data]\",\n",
    "        \"donorProjectList\": [\"Project1\", \"Project2\", \"Project3\"],\n",
    "        \"donationAmount\": 2500\n",
    "    },\n",
    "    {\n",
    "        \"donorName\": \"Donor4 name\",\n",
    "        \"donorEmail\": \"email@undp.org\",\n",
    "        \"donorWebsite\": \"https://www.undp.org\",\n",
    "        \"donorPhotoUrl\": \"data:image/png;base64,[image_data]\",\n",
    "        \"donorProjectList\": [\"UNDP Data Bank\", \"Project1\", \"Project2\", \"Project3\"],\n",
    "        \"donationAmount\": 2500\n",
    "    }\n",
    "]\n",
    "\n",
    "contribution = \"contribution\"\n",
    "dataReliability = \"dataReliability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data has been successfully converted to JSON and saved to '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/project_data.json'\n"
     ]
    }
   ],
   "source": [
    "# Detect the encoding of the CSV file\n",
    "with open(csv_file_path, 'rb') as file:\n",
    "    encoding = chardet.detect(file.read(10000))['encoding']\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path, encoding=encoding)\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame using the detected encoding\n",
    "df[\"executingAgency\"] = [executingAgency[0]] * len(df)\n",
    "df[\"donor\"] = [donors[i % len(donors)] for i in range(len(df))]\n",
    "\n",
    "df[\"contribution\"] = contribution\n",
    "df[\"dataReliability\"] = dataReliability\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "data = df.to_dict(orient='records')\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"CSV data has been successfully converted to JSON and saved to '{json_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Coordinates' field removed and updated data saved to /Users/izzymohamed/Desktop/Horizon Scanner/egypt-horizon-scanner/JSON/Response Now/Interventions Mapping/interventions_governorate_map1.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to remove the 'Coordinates' field from the JSON data\n",
    "def remove_coordinates(json_data):\n",
    "    for item in json_data:\n",
    "        if 'Coordinates' in item:\n",
    "            del item['Coordinates']\n",
    "    return json_data\n",
    "\n",
    "# Read the JSON file\n",
    "input_file = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt-horizon-scanner/JSON/Response Now/Interventions Mapping/interventions_governorate_map.json'\n",
    "output_file = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt-horizon-scanner/JSON/Response Now/Interventions Mapping/interventions_governorate_map1.json'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Remove the 'Coordinates' field\n",
    "updated_data = remove_coordinates(data)\n",
    "\n",
    "# Write the updated JSON data back to a file\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(updated_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"'Coordinates' field removed and updated data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_features(features):\n",
    "    processed_features = []\n",
    "    id_counter = 1  # Initialize a counter for assigning IDs\n",
    "    \n",
    "    for feature in features:\n",
    "        geometry = feature.get('geometry', {})\n",
    "        properties = feature.get('properties', {})\n",
    "        \n",
    "        # Determine if the feature is a governorate or a municipal division\n",
    "        feature_type = 'Governorate' if 'Governorate' in properties.get('ADM1_EN', '') else 'MunicipalDivision'\n",
    "        feature_id = id_counter\n",
    "        id_counter += 1  # Increment the ID counter for the next feature\n",
    "\n",
    "        # Initialize coordinates as None\n",
    "        coordinates = None\n",
    "        \n",
    "        # Check if geometry type is Polygon or MultiPolygon and convert to Point\n",
    "        coordinates = geometry\n",
    "        # if geometry['type'] in ['Polygon', 'MultiPolygon'] and geometry['coordinates']:\n",
    "        #     coords = geometry['coordinates'][0][0]  # Use the first point of the first linear ring\n",
    "        #     if coords and isinstance(coords, list):\n",
    "        #         # Convert Polygon to Point by selecting the first point (as an example)\n",
    "        #         coordinates = { \"type\": \"Point\", \"coordinates\": [coords[0], coords[1]] }\n",
    "        \n",
    "        processed_feature = {\n",
    "            'ID': feature_id,\n",
    "            'Type': feature_type,\n",
    "            'Governorate_Name_EN': properties.get('ADM1_EN', ''),\n",
    "            'Governorate_Name_AR': properties.get('ADM1_AR', ''),\n",
    "            'Governorate_PCODE': properties.get('ADM1_PCODE', ''),\n",
    "            'Country_EN': properties.get('ADM0_EN', ''),\n",
    "            'Country_AR': properties.get('ADM0_AR', ''),\n",
    "            'Country_PCODE': properties.get('ADM0_PCODE', ''),\n",
    "            # 'Coordinates': coordinates,\n",
    "        }\n",
    "        \n",
    "        # Only include municipal division details if ADM2 fields are present\n",
    "        if 'ADM2_EN' in properties:\n",
    "            processed_feature.update({\n",
    "                'Municipal_Division_Type': None,\n",
    "                'Municipal_Division_Name_EN': properties.get('ADM2_EN', ''),\n",
    "                'Municipal_Division_Name_AR': properties.get('ADM2_AR', ''),\n",
    "                'Municipal_Division_PCODE': properties.get('ADM2_PCODE', ''),\n",
    "            })\n",
    "        \n",
    "        processed_features.append(processed_feature)\n",
    "    \n",
    "    return processed_features\n",
    "\n",
    "def extract_data_from_json(json_file_path, csv_file_path, json_output_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        features = data.get('features', [])\n",
    "        processed_features = process_features(features)\n",
    "        \n",
    "        # Convert to DataFrame for CSV output\n",
    "        df = pd.DataFrame(processed_features)\n",
    "        df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "        print(f\"Data successfully written to {csv_file_path}\")\n",
    "        \n",
    "        # Output to JSON file\n",
    "        with open(json_output_path, 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump(processed_features, jsonfile, ensure_ascii=False, indent=4)\n",
    "        print(f\"Data successfully written to {json_output_path}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {json_file_path} does not exist.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"The file {json_file_path} is not a valid JSON or GeoJSON file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder path to your JSON file\n",
    "json_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/governorates.json'\n",
    "csv_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/csv/interventions_governorate_map.csv'\n",
    "json_output_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/interventions_governorate_map.json'\n",
    "extract_data_from_json(json_file_path, csv_file_path, json_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder path to your JSON file\n",
    "json_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/municipal_divisions.json'\n",
    "csv_file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/csv/interventions_municipal_division_map.csv'\n",
    "json_output_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt_horizon_scanner_frontend/assets/json/interventions_municipal_division_map.json'\n",
    "extract_data_from_json(json_file_path, csv_file_path, json_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = '/Users/izzymohamed/Desktop/Horizon Scanner/egypt-horizon-scanner/JSON/Response Now/Interventions Mapping/interventions_municipal_division_map copy.json'\n",
    "\n",
    "# Read the JSON data from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Remove the 'Coordinates' key from each item in the JSON data if it exists\n",
    "if isinstance(data, list):  # If the data is a list of dictionaries\n",
    "    for item in data:\n",
    "        item.pop('Coordinates', None)\n",
    "elif isinstance(data, dict):  # If the data is a single dictionary\n",
    "    data.pop('Coordinates', None)\n",
    "\n",
    "# Save the modified data back to the same JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(\"Coordinates key has been removed and the file has been updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open(\"/Users/izzymohamed/Desktop/Horizon Scanner/egypt-horizon-scanner/JSON/Digital Avatar/Dimensions.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "    # Convert \"Data Visualization\" from string to list of strings\n",
    "    for item in data:\n",
    "        if \"Data Visualization\" in item:\n",
    "            visualization = item[\"Data Visualization\"]\n",
    "            if visualization and visualization.lower() not in [\"none\", \"null\"]:\n",
    "                split_visualization = []\n",
    "                for v in visualization.split(\", \"):\n",
    "                    split_visualization.extend([x.strip() for x in v.split(\"and \")])\n",
    "                    split_visualization.extend([x.strip() for x in v.split(\"or \")])\n",
    "                # Remove duplicates\n",
    "                item[\"Data Visualization\"] = list(set(split_visualization))\n",
    "\n",
    "# Save the modified data back to the JSON file\n",
    "# output_file_path = \"/Users/izzymohamed/Desktop/Horizon Scanner/egypt-horizon-scanner/JSON/Digital Avatar/Modified_Dimensions.json\"\n",
    "# with open(output_file_path, 'w') as output_file:\n",
    "#     json.dump(data, output_file, indent=4)\n",
    "\n",
    "# print(\"Modified JSON data has been saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "descriptions = [\n",
    "    \"I love this product, it works great!\",\n",
    "    \"The movie was terrible and boring.\",\n",
    "    \"This is a neutral statement about weather.\",\n",
    "    \"What a wonderful day to have a picnic!\",\n",
    "    \"I am disappointed with the service.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"jysh1023/tiny-bert-sst2-distilled\"\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analysis_model = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "text_classifier = pipeline(\"text-classification\", model=model_name)\n",
    "\n",
    "# Load the model and tokenizer for custom function\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text, model, tokenizer, pipeline):\n",
    "    # Encode the text using the tokenizer\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Perform the prediction\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probabilities = tf.nn.softmax(outputs[0], axis=-1)\n",
    "\n",
    "    # Get the predicted class (index with the highest probability)\n",
    "    predicted_class_index = tf.argmax(probabilities, axis=-1).numpy()[0]\n",
    "    \n",
    "    # Mapping labels to more readable form\n",
    "    label_map = {0: \"Negative\", 1: \"Positive\"}  # Update this map based on your model.js's training\n",
    "    predicted_class = label_map[predicted_class_index]\n",
    "\n",
    "    return predicted_class, probabilities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for description in descriptions:\n",
    "    # Perform sentiment analysis\n",
    "    sentiment, probabilities = sentiment_analysis(description, model, tokenizer, text_classifier)\n",
    "    print(f\"Text: {description}\")\n",
    "    print(f\"Classification: {sentiment}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Classify the texts and print the results\n",
    "results = text_classifier(descriptions)\n",
    "\n",
    "for text, result in zip(descriptions, results):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Classification: {result['label']}, Score: {result['score']:.4f}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging_issues = [\n",
    "    \"Water Issue\", \"Climate Change\", \"Food Security\", \"Health Crisis\", \"Economic Recession\",\n",
    "    \"Energy Crisis\", \"Biodiversity Loss\", \"Political Instability\", \"Education Gap\", \"Technological Disruption\",\n",
    "    \"Housing Shortage\", \"Transportation Problems\", \"Waste Management\", \"Cultural Decline\", \"Social Inequality\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Define a function to tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Assume 'my_dataset' is already loaded with the format [{'text': 'example text', 'label': 0}, ...]\n",
    "dataset = load_dataset('csv', data_files='path_to_your_data.csv')\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define the model\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(emerging_issues))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "mongo_uri = 'mongodb+srv://doadmin:73Le6F4d2hZ9K8Y0@dbaas-db-5626135-310aba91.mongo.ondigitalocean.com/egypt-horizon-scanner?replicaSet=dbaas-db-5626135&tls=true&authSource=admin'\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[\"egypt-horizon-scanner\"]\n",
    "collection = db[\"emergence_issue_of_the_month_data\"]\n",
    "\n",
    "# Read data from MongoDB collection into a DataFrame\n",
    "data = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by emergingIssue\n",
    "grouped_data = data.groupby('emergingIssue').size().reset_index(name='count')\n",
    "\n",
    "issues_dic = {}\n",
    "\n",
    "# save the each grouped data into its own df\n",
    "for issue in grouped_data['emergingIssue']:\n",
    "    issue_df = data[data['emergingIssue'] == issue]\n",
    "    issues_dic[issue] = issue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Counting the total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters in {model_name}: {total_params}\")\n",
    "\n",
    "# Load a pre-trained model for summarization using the pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def generate_summary(text, model, tokenizer):\n",
    "    # Check the length of tokenized input\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs, max_length=300, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, df in issues_dic.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    # Combine all descriptions into one text for summarization\n",
    "    combined_text = ' '.join(df['description'].tolist())\n",
    "    print(f\"Combined Text:\\n{combined_text}\")\n",
    "    # Generate and print the summary paragraph\n",
    "    summary_paragraph = generate_summary(combined_text, model, tokenizer)\n",
    "    print(f\"Summary Paragraph:\\n{summary_paragraph}\")\n",
    "    print(\"-\" * 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
