{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandoc\n",
      "  Using cached pandoc-2.3.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-docx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.1.2)\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: PyMuPDF in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.4)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.40.1)\n",
      "Requirement already satisfied: mammoth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.1)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: doc2docx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.4)\n",
      "Requirement already satisfied: pytesseract in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: appscript<2.0.0,>=1.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from doc2docx) (1.2.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from doc2docx) (4.65.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/izzymohamed/Library/Python/3.11/lib/python/site-packages (from pytesseract) (24.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytesseract) (9.4.0)\n",
      "Requirement already satisfied: lxml>=4.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from appscript<2.0.0,>=1.2.2->doc2docx) (4.9.2)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: textract in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.6.5)\n",
      "Requirement already satisfied: aspose-words in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (24.5.0)\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (1.10.3)\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (4.8.2)\n",
      "Requirement already satisfied: chardet==3.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (3.0.4)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (0.8)\n",
      "Requirement already satisfied: extract-msg<=0.29.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (0.28.7)\n",
      "Requirement already satisfied: pdfminer.six==20191110 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (20191110)\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (0.6.23)\n",
      "Requirement already satisfied: six~=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (1.12.0)\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (3.8.1)\n",
      "Requirement already satisfied: xlrd~=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from textract) (1.2.0)\n",
      "Requirement already satisfied: pycryptodome in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfminer.six==20191110->textract) (3.20.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4~=4.8.0->textract) (2.4)\n",
      "Requirement already satisfied: imapclient==2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
      "Requirement already satisfied: olefile>=0.46 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from extract-msg<=0.29.*->textract) (0.47)\n",
      "Requirement already satisfied: tzlocal>=2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from extract-msg<=0.29.*->textract) (5.2)\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-pptx~=0.6.18->textract) (4.9.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-pptx~=0.6.18->textract) (3.2.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandoc python-docx openpyxl PyMuPDF transformers mammoth pywin32 Spire.Doc\n",
    "%pip install doc2docx pytesseract\n",
    "%pip install textract aspose-words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "import fitz  # PyMuPDF\n",
    "from openpyxl import load_workbook\n",
    "import aspose.words as aw\n",
    "import spacy\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load a pre-trained NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of questions to extract specific fields\n",
    "questions = {\n",
    "    \"id\": \"What is the project ID?\",\n",
    "    \"projectNo\": \"What is the project number?\",\n",
    "    \"projectName\": \"What is the name of the project?\",\n",
    "    \"projectDetail\": \"Can you provide a detailed description of the project?\",\n",
    "    \"photoURL\": \"What is the photo URL associated with the project?\", \n",
    "    \"executingAgency\": \"Who is the executing agency for the project?\",\n",
    "    \"status\": \"What is the status of the project? Is it completed, in progress, or not started?\",\n",
    "    \"theme\": \"What are the main themes or focus areas of the project?\",\n",
    "    \"estimatedCost\": \"What is the estimated cost of the project?\",\n",
    "    \"budget\": \"What is the budget allocation for the project?\",\n",
    "    \"totalDonatedAmount\": \"What is the total amount donated to the project?\",\n",
    "    \"startDate\": \"What is the start date of the project?\",\n",
    "    \"endDate\": \"What is the end date of the project?\",\n",
    "    # \"Latitude\": \"What are the latitude coordinates of the project location?\",\n",
    "    # \"Longitude\": \"What are the longitude coordinates of the project location?\",\n",
    "    \"Locality_Name_EN\": \"What is the locality name in English?\",\n",
    "    \"Locality_Name_AR\": \"What is the locality name in Arabic?\",\n",
    "    \"Locality_PCODE\": \"What is the locality postal code?\",\n",
    "    \"City_Name_EN\": \"What is the city name in English?\",\n",
    "    \"City_Name_AR\": \"What is the city name in Arabic?\",\n",
    "    \"City_PCODE\": \"What is the city postal code?\",\n",
    "    \"District_Name_EN\": \"What is the district name in English?\",\n",
    "    \"District_Name_AR\": \"What is the district name in Arabic?\",\n",
    "    \"District_PCODE\": \"What is the district postal code?\",\n",
    "    \"Municipal_Division_Type\": \"What is the municipal division type (kism, markaz, new city, or police-administered)?\",\n",
    "    \"Municipal_Division_Name_EN\": \"What is the municipal division name in English?\",\n",
    "    \"Municipal_Division_Name_AR\": \"What is the municipal division name in Arabic?\",\n",
    "    \"Municipal_Division_PCODE\": \"What is the municipal division postal code?\",\n",
    "    \"Governorate_Name_EN\": \"What is the governorate name in English?\",\n",
    "    \"Governorate_Name_AR\": \"What is the governorate name in Arabic?\",\n",
    "    \"Governorate_PCODE\": \"What is the governorate postal code?\",\n",
    "    \"State_Name_EN\": \"What is the state name in English?\",\n",
    "    \"State_Name_AR\": \"What is the state name in Arabic?\",\n",
    "    \"State_PCODE\": \"What is the state postal code?\",\n",
    "    \"Province_Name_EN\": \"What is the province name in English?\",\n",
    "    \"Province_Name_AR\": \"What is the province name in Arabic?\",\n",
    "    \"Province_PCODE\": \"What is the province postal code?\",\n",
    "    \"Region_Name_EN\": \"What is the region name in English?\",\n",
    "    \"Region_Name_AR\": \"What is the region name in Arabic?\",\n",
    "    \"Region_PCODE\": \"What is the region postal code?\",\n",
    "    \"Country_EN\": \"What is the country name in English?\",\n",
    "    \"Country_AR\": \"What is the country name in Arabic?\",\n",
    "    \"Country_PCODE\": \"What is the country postal code?\",\n",
    "    \"donor\": \"Who are the donors for the project?\",\n",
    "    \"contribution\": \"What contributions have been made to the project?\",\n",
    "    \"dataReliability\": \"What is the data reliability rating for the project information?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t1.\tid: 1827\n",
    "\t2.\tprojectNo: PIMS 1237 CC MSP\n",
    "\t3.\tprojectName: Introduction of Vehicle Electric Bus Technology and Hybrid-Electric Bus Technology in Egypt – Phase 1a\n",
    "\t4.\tprojectDetail:\n",
    "\t\t•\tThe project aimed to introduce electric and hybrid-electric buses in Egypt to reduce pollution, improve public health, and protect national monuments from degradation due to heavy-duty buses.\n",
    "\t\t•\tPhase 1a involved testing two electric buses, training local staff on maintenance and operations, and planning for subsequent phases.\n",
    "\t5.\tphotoURL: Not provided\n",
    "\t6.\texecutingAgency: [Egyptian Environmental Affairs Agency (EEAA), Social Fund for Development (SFD)]\n",
    "\t7.\tstatus: Completed (Phase 1a)\n",
    "\t8.\ttheme: [Climate Change, Sustainable Transportation, Public Health, Cultural Heritage Protection]\n",
    "\t9.\testimatedCost: USD 1.714 million\n",
    "\t10.\tbudget:\n",
    "\t\t•\tGEF: USD 0.7486 million\n",
    "\t\t•\tEEAA: USD 0.3154 million\n",
    "\t\t•\tSFD: USD 0.1 million\n",
    "\t\t•\tIn-kind contribution: USD 0.55 million\n",
    "\t11.\ttotalDonatedAmount: USD 0.7486 million\n",
    "\t12.\tstartDate: March 2000\n",
    "\t13.\tendDate: June 2006 (Phase 1a)\n",
    "\t14.\tLatitude: Not provided\n",
    "\t15.\tLongitude: Not provided\n",
    "\t16.\tLocality_Name_EN: Giza, Luxor\n",
    "\t17.\tLocality_Name_AR: الجيزة، الأقصر\n",
    "\t18.\tLocality_PCODE: Not provided\n",
    "\t19.\tCity_Name_EN: Cairo\n",
    "\t20.\tCity_Name_AR: القاهرة\n",
    "\t21.\tCity_PCODE: Not provided\n",
    "\t22.\tDistrict_Name_EN: Not provided\n",
    "\t23.\tDistrict_Name_AR: Not provided\n",
    "\t24.\tDistrict_PCODE: Not provided\n",
    "\t25.\tMunicipal_Division_Type: Not provided\n",
    "\t26.\tMunicipal_Division_Name_EN: Not provided\n",
    "\t27.\tMunicipal_Division_Name_AR: Not provided\n",
    "\t28.\tMunicipal_Division_PCODE: Not provided\n",
    "\t29.\tGovernorate_Name_EN: Giza Governorate, Luxor Governorate\n",
    "\t30.\tGovernorate_Name_AR: محافظة الجيزة، محافظة الأقصر\n",
    "\t31.\tGovernorate_PCODE: Not provided\n",
    "\t32.\tState_Name_EN: Not applicable\n",
    "\t33.\tState_Name_AR: Not applicable\n",
    "\t34.\tState_PCODE: Not applicable\n",
    "\t35.\tProvince_Name_EN: Not applicable\n",
    "\t36.\tProvince_Name_AR: Not applicable\n",
    "\t37.\tProvince_PCODE: Not applicable\n",
    "\t38.\tRegion_Name_EN: Not applicable\n",
    "\t39.\tRegion_Name_AR: Not applicable\n",
    "\t40.\tRegion_PCODE: Not applicable\n",
    "\t41.\tCountry_EN: Egypt\n",
    "\t42.\tCountry_AR: مصر\n",
    "\t43.\tCountry_PCODE: Not provided\n",
    "\t44.\tdonor: [Global Environment Facility (GEF)]\n",
    "\t45.\tcontribution: USD 0.7486 million (GEF), USD 0.3154 million (EEAA), USD 0.1 million (SFD)\n",
    "\t46.\tdataReliability: Information derived from final evaluation reports and project documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d0cd10173942a98f3c4ab629385e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2030f15ad58948a0b432c996a60f64fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/140M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at NeuML/bert-small-cord19qa were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3763bcec0c90492583398abd529c5050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbb386015a946b6b48d2b331ee6de26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c255898a7a4492a949dc3ed462e1543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the question-answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"NeuML/bert-small-cord19qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract information based on questions\n",
    "def extract_info(text, questions):\n",
    "    extracted_info = {}\n",
    "    for key, question in questions.items():\n",
    "        result = qa_pipeline(question=question, context=text)\n",
    "        extracted_info[key] = result['answer']\n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from XLSX\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert DOC to DOCX and then extract text\n",
    "def convert_doc_to_docx(doc_path):\n",
    "    docx_path = doc_path + \"x\"\n",
    "    doc = aw.Document(doc_path)\n",
    "    doc.save(docx_path)\n",
    "    return docx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from DOC\n",
    "def extract_text_from_doc(doc_path):\n",
    "    docx_path = convert_doc_to_docx(doc_path)\n",
    "    text = extract_text_from_docx(docx_path)\n",
    "    \n",
    "    os.remove(docx_path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from XLSX\n",
    "def extract_data_from_xlsx(xlsx_path):\n",
    "    wb = load_workbook(xlsx_path)\n",
    "    ws = wb.active\n",
    "    data = \"\\n\".join([\"\\t\".join(map(str, row)) for row in ws.iter_rows(values_only=True)])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to extract text based on file type\n",
    "def extract_text_from_file(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.doc'):\n",
    "        return extract_text_from_doc(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        return extract_data_from_xlsx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract named entities from text using a specific model\n",
    "def extract_entities(text):\n",
    "    model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "    entities = nlp(text)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image_path):\n",
    "    return pytesseract.image_to_string(Image.open(image_path))\n",
    "\n",
    "# Function to extract entities from text\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize_text(text, model=\"facebook/bart-large-cnn\"):\n",
    "    summarizer = pipeline(\"summarization\", model=model)\n",
    "    return summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
    "\n",
    "# Function to answer questions based on text\n",
    "def answer_question(text, question, model=\"deepset/roberta-base-squad2\"):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model)\n",
    "    return qa_pipeline(question=question, context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map entities to a predefined schema\n",
    "def map_entities_to_schema(entities):\n",
    "    project_data = {\n",
    "        \"id\": \"\",\n",
    "        \"projectNo\": None,\n",
    "        \"projectName\": \"\",\n",
    "        \"projectDetail\": \"\",\n",
    "        \"photoURL\": \"\",\n",
    "        \"executingAgency\": [],\n",
    "        \"status\": \"\",\n",
    "        \"theme\": [],\n",
    "        \"estimatedCost\": None,\n",
    "        \"budget\": None,\n",
    "        \"totalDonatedAmount\": None,\n",
    "        \"startDate\": \"\",\n",
    "        \"endDate\": \"\",\n",
    "        \"Latitude\": None,\n",
    "        \"Longitude\": None,\n",
    "        \"Locality_Name_EN\": \"\",\n",
    "        \"Locality_Name_AR\": \"\",\n",
    "        \"Locality_PCODE\": \"\",\n",
    "        \"City_Name_EN\": \"\",\n",
    "        \"City_Name_AR\": \"\",\n",
    "        \"City_PCODE\": \"\",\n",
    "        \"District_Name_EN\": \"\",\n",
    "        \"District_Name_AR\": \"\",\n",
    "        \"District_PCODE\": \"\",\n",
    "        \"Municipal_Division_Type\": \"\",\n",
    "        \"Municipal_Division_Name_EN\": \"\",\n",
    "        \"Municipal_Division_Name_AR\": \"\",\n",
    "        \"Municipal_Division_PCODE\": \"\",\n",
    "        \"Governorate_Name_EN\": \"\",\n",
    "        \"Governorate_Name_AR\": \"\",\n",
    "        \"Governorate_PCODE\": \"\",\n",
    "        \"State_Name_EN\": \"\",\n",
    "        \"State_Name_AR\": \"\",\n",
    "        \"State_PCODE\": \"\",\n",
    "        \"Province_Name_EN\": \"\",\n",
    "        \"Province_Name_AR\": \"\",\n",
    "        \"Province_PCODE\": \"\",\n",
    "        \"Region_Name_EN\": \"\",\n",
    "        \"Region_Name_AR\": \"\",\n",
    "        \"Region_PCODE\": \"\",\n",
    "        \"Country_EN\": \"\",\n",
    "        \"Country_AR\": \"\",\n",
    "        \"Country_PCODE\": \"\",\n",
    "        \"donor\": [],\n",
    "        \"contribution\": \"\",\n",
    "        \"dataReliability\": \"\"\n",
    "    }\n",
    "\n",
    "    for entity in entities:\n",
    "        if entity['entity_group'] == 'ID':\n",
    "            project_data['id'] = entity['word']\n",
    "        elif entity['entity_group'] == 'PROJECT_NO':\n",
    "            project_data['projectNo'] = int(entity['word'])\n",
    "        elif entity['entity_group'] == 'PROJECT_NAME':\n",
    "            project_data['projectName'] += entity['word'] + \" \"\n",
    "        elif entity['entity_group'] == 'PROJECT_DETAIL':\n",
    "            project_data['projectDetail'] += entity['word'] + \" \"\n",
    "        elif entity['entity_group'] == 'STATUS':\n",
    "            project_data['status'] = entity['word']\n",
    "        elif entity['entity_group'] == 'THEME':\n",
    "            project_data['theme'].append(entity['word'])\n",
    "        elif entity['entity_group'] == 'ESTIMATED_COST':\n",
    "            project_data['estimatedCost'] = float(entity['word'].replace(',', ''))\n",
    "        elif entity['entity_group'] == 'BUDGET':\n",
    "            project_data['budget'] = float(entity['word'].replace(',', ''))\n",
    "        elif entity['entity_group'] == 'TOTAL_DONATED_AMOUNT':\n",
    "            project_data['totalDonatedAmount'] = float(entity['word'].replace(',', ''))\n",
    "        elif entity['entity_group'] == 'START_DATE':\n",
    "            project_data['startDate'] = entity['word']\n",
    "        elif entity['entity_group'] == 'END_DATE':\n",
    "            project_data['endDate'] = entity['word']\n",
    "        elif entity['entity_group'] == 'LATITUDE':\n",
    "            project_data['Latitude'] = float(entity['word'])\n",
    "        elif entity['entity_group'] == 'LONGITUDE':\n",
    "            project_data['Longitude'] = float(entity['word'])\n",
    "        elif entity['entity_group'] == 'LOCALITY_NAME_EN':\n",
    "            project_data['Locality_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'LOCALITY_NAME_AR':\n",
    "            project_data['Locality_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'LOCALITY_PCODE':\n",
    "            project_data['Locality_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'CITY_NAME_EN':\n",
    "            project_data['City_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'CITY_NAME_AR':\n",
    "            project_data['City_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'CITY_PCODE':\n",
    "            project_data['City_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'DISTRICT_NAME_EN':\n",
    "            project_data['District_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'DISTRICT_NAME_AR':\n",
    "            project_data['District_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'DISTRICT_PCODE':\n",
    "            project_data['District_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'MUNICIPAL_DIVISION_TYPE':\n",
    "            project_data['Municipal_Division_Type'] = entity['word']\n",
    "        elif entity['entity_group'] == 'MUNICIPAL_DIVISION_NAME_EN':\n",
    "            project_data['Municipal_Division_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'MUNICIPAL_DIVISION_NAME_AR':\n",
    "            project_data['Municipal_Division_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'MUNICIPAL_DIVISION_PCODE':\n",
    "            project_data['Municipal_Division_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'GOVERNORATE_NAME_EN':\n",
    "            project_data['Governorate_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'GOVERNORATE_NAME_AR':\n",
    "            project_data['Governorate_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'GOVERNORATE_PCODE':\n",
    "            project_data['Governorate_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'STATE_NAME_EN':\n",
    "            project_data['State_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'STATE_NAME_AR':\n",
    "            project_data['State_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'STATE_PCODE':\n",
    "            project_data['State_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'PROVINCE_NAME_EN':\n",
    "            project_data['Province_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'PROVINCE_NAME_AR':\n",
    "            project_data['Province_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'PROVINCE_PCODE':\n",
    "            project_data['Province_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'REGION_NAME_EN':\n",
    "            project_data['Region_Name_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'REGION_NAME_AR':\n",
    "            project_data['Region_Name_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'REGION_PCODE':\n",
    "            project_data['Region_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'COUNTRY_EN':\n",
    "            project_data['Country_EN'] = entity['word']\n",
    "        elif entity['entity_group'] == 'COUNTRY_AR':\n",
    "            project_data['Country_AR'] = entity['word']\n",
    "        elif entity['entity_group'] == 'COUNTRY_PCODE':\n",
    "            project_data['Country_PCODE'] = entity['word']\n",
    "        elif entity['entity_group'] == 'DONOR':\n",
    "            project_data['donor'].append(entity['word'])\n",
    "        elif entity['entity_group'] == 'CONTRIBUTION':\n",
    "            project_data['contribution'] = entity['word']\n",
    "        elif entity['entity_group'] == 'DATA_RELIABILITY':\n",
    "            project_data['dataReliability'] = entity['word']\n",
    "    \n",
    "    return project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract information from files and save to JSON\n",
    "def extract_info_from_files(file_paths, json_path):\n",
    "    texts = [extract_text_from_file(file_path) for file_path in file_paths]\n",
    "    combined_text = \"\\n\".join(texts)\n",
    "    \n",
    "    # entities = extract_entities(combined_text)\n",
    "    # Extract the information\n",
    "    extracted_information = extract_info(combined_text, questions)\n",
    "    # project_data = map_entities_to_schema(extracted_information)\n",
    "\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json.dump(extracted_information, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "\"/Users/izzymohamed/Downloads/Documents/PIMS 1237 CC MSP - ELECTRIC BUSES/Electric_buses_eval-Executive_Summary.doc\",\n",
    "\"/Users/izzymohamed/Downloads/Documents/PIMS 1237 CC MSP - ELECTRIC BUSES/Electric_buses_Final_Evaluation_report.doc\",\n",
    "\"/Users/izzymohamed/Downloads/Documents/PIMS 1237 CC MSP - ELECTRIC BUSES/TERMS_OF_REFERENCE.doc\",\n",
    "\"/Users/izzymohamed/Downloads/Documents/PIMS 1237 CC MSP - ELECTRIC BUSES/report.xlsx\"\n",
    "]\n",
    "\n",
    "json_path = \"output.json\"\n",
    "extract_info_from_files(file_paths, json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
